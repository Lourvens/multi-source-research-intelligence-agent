# AGENT.md - Multi-Source Research Intelligence Platform

## ğŸ“‹ Project Overview

**Project Name**: Multi-Source Research Intelligence Platform (MSRIP)

**Version**: 1.0.0 - Phase 1 (Foundation)

**Purpose**: Build an agentic RAG system that autonomously searches academic papers, patents, news, and datasets to generate comprehensive research reports with proper citations and contradiction analysis.

**Current Phase**: Phase 1 - Foundation & Basic RAG Setup

---

## ğŸ¯ Project Vision & Goals

### Primary Objectives
1. **Autonomous Research**: Enable researchers to get comprehensive answers by querying multiple authoritative sources simultaneously
2. **Citation Integrity**: Every claim must be traceable to its source with proper academic citation
3. **Contradiction Detection**: Identify conflicting information across sources and present balanced analysis
4. **Scalability**: Design for future expansion from 1 source (Phase 1) to 10+ sources (Phase 10)

### Success Metrics
- **Retrieval Relevance**: >80% of retrieved documents rated as relevant
- **Answer Accuracy**: >85% factually correct (human evaluation)
- **Citation Coverage**: 100% of claims cited to source documents
- **Response Time**: <60 seconds for complex multi-source queries (Phase 8+)
- **User Satisfaction**: >4.0/5.0 rating from test users

---

## ğŸ—ï¸ System Architecture Principles

### 1. **Modularity First**
- Each component (fetcher, processor, vector store, agent) is independently testable
- Interfaces are clearly defined between components
- New data sources can be added without modifying existing code

### 2. **Progressive Complexity**
- Phase 1: Single source (ArXiv), basic RAG
- Phase 2-3: Multi-source, routing logic
- Phase 4-6: Agents, self-reflection, query rewriting
- Phase 7-10: Orchestration, synthesis, production deployment

### 3. **Data-Centric Design**
- Rich metadata preservation at every stage
- Traceability from answer â†’ chunk â†’ source document
- Versioning of processed data for reproducibility

### 4. **Agent Autonomy**
- Agents make decisions based on query analysis
- Self-evaluation and iterative improvement
- Fallback mechanisms for failure scenarios

---

## ğŸ“ Architectural Rules & Guidelines

### Rule 1: **Single Source of Truth**
- Raw data from APIs is saved immediately (JSON format)
- All processing derives from these raw files
- Never modify raw data; create processed versions

**Example**:
```
data/
â”œâ”€â”€ raw/
â”‚   â””â”€â”€ arxiv_papers_2024-01-15.json  # Never modified
â””â”€â”€ processed/
    â””â”€â”€ arxiv_chunks_2024-01-15.json   # Derived from raw
```

### Rule 2: **Metadata is Sacred**
Every document chunk MUST contain:
- `source`: Origin (arxiv, pubmed, news, etc.)
- `paper_id`: Unique identifier
- `title`: Document title
- `authors`: Creator attribution
- `published`: Publication date (ISO 8601 format)
- `pdf_url` or `url`: Link to original source
- `chunk_id`: Unique chunk identifier
- `chunk_index`: Position in original document

**Why**: Citations and source verification depend on complete metadata

### Rule 3: **Idempotency & Reproducibility**
- Running the same pipeline twice with same input produces identical output
- All random seeds are fixed
- API responses are cached when possible
- Version control includes data provenance

### Rule 4: **Rate Limiting & API Respect**
- Implement delays between API calls (3-5 seconds)
- Respect API rate limits explicitly
- Cache API responses to avoid redundant calls
- Use exponential backoff for retries

**Implementation**:
```python
# Good
time.sleep(3)  # Be nice to API servers
result = fetch_with_retry(url, max_retries=3, backoff=2)

# Bad
for i in range(1000):
    fetch(url)  # Will get rate limited or banned
```

### Rule 5: **Error Handling is Non-Negotiable**
Every external call MUST have:
- Try-except blocks with specific exception types
- Logging of errors with context
- Graceful degradation when possible
- User-friendly error messages

**Template**:
```python
try:
    result = api_call()
except RateLimitError as e:
    logger.warning(f"Rate limited: {e}. Waiting 60s...")
    time.sleep(60)
    result = api_call()
except APIError as e:
    logger.error(f"API error: {e}")
    return fallback_result()
except Exception as e:
    logger.critical(f"Unexpected error: {e}")
    raise
```

### Rule 6: **Logging Standards**
All components must log:
- INFO: Normal operations (papers fetched, chunks created)
- WARNING: Degraded performance (rate limits, retries)
- ERROR: Failures with recovery attempts
- CRITICAL: Unrecoverable failures

**Format**: `[TIMESTAMP] [LEVEL] [COMPONENT] Message`

### Rule 7: **Configuration Over Hardcoding**
All configurable values go in:
- `.env` for secrets (API keys)
- `config.yaml` for parameters (chunk size, model names)
- Never hardcode API keys, file paths, or magic numbers

### Rule 8: **Testing at Every Phase**
Before moving to next phase:
- âœ… Unit tests for each function
- âœ… Integration tests for pipeline
- âœ… Manual evaluation of output quality
- âœ… Performance benchmarks logged

### Rule 9: **Documentation is Development**
- Every function has docstring with Args, Returns, Raises
- README updated after each phase
- Architecture diagrams for complex workflows
- CHANGELOG.md tracks all changes

### Rule 10: **Privacy & Ethics**
- No storage of API keys in code or git
- User queries are not logged permanently (GDPR compliance)
- Fair use of academic papers (no full-text storage without permission)
- Attribution to all sources

---

## ğŸ—‚ï¸ Project Structure Standards

```
research-rag/
â”œâ”€â”€ .env                          # API keys (NEVER commit)
â”œâ”€â”€ .env.example                  # Template for .env
â”œâ”€â”€ .gitignore                    # Ignore secrets, data, vector_db
â”œâ”€â”€ requirements.txt              # Python dependencies
â”œâ”€â”€ config.yaml                   # Configuration parameters
â”œâ”€â”€ README.md                     # User-facing documentation
â”œâ”€â”€ AGENT.md                      # This file - rules and architecture
â”œâ”€â”€ CHANGELOG.md                  # Version history
â”œâ”€â”€ notebooks/                    # Jupyter notebooks for exploration
â”‚   â”œâ”€â”€ phase1_basic_rag.ipynb
â”‚   â”œâ”€â”€ phase2_multi_source.ipynb
â”‚   â””â”€â”€ experiments/              # Ad-hoc experiments
â”œâ”€â”€ src/                          # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                 # Config loading utilities
â”‚   â”œâ”€â”€ ingestion/                # Data fetching & processing
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ arxiv_fetcher.py
â”‚   â”‚   â”œâ”€â”€ pubmed_fetcher.py     # Phase 2+
â”‚   â”‚   â”œâ”€â”€ document_processor.py
â”‚   â”‚   â””â”€â”€ base_fetcher.py       # Abstract base class
â”‚   â”œâ”€â”€ vector_store/             # Vector database management
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ chroma_store.py
â”‚   â”‚   â””â”€â”€ store_interface.py    # Abstract interface
â”‚   â”œâ”€â”€ agents/                   # Agent implementations (Phase 3+)
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ router_agent.py
â”‚   â”‚   â”œâ”€â”€ grader_agent.py
â”‚   â”‚   â”œâ”€â”€ rewriter_agent.py
â”‚   â”‚   â””â”€â”€ orchestrator.py       # Phase 8+
â”‚   â”œâ”€â”€ rag/                      # RAG chains
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ basic_chain.py
â”‚   â”‚   â””â”€â”€ agentic_chain.py      # Phase 4+
â”‚   â””â”€â”€ utils/                    # Utilities
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ logging_config.py
â”‚       â”œâ”€â”€ metrics.py
â”‚       â””â”€â”€ citation_formatter.py
â”œâ”€â”€ tests/                        # Test suite
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ test_arxiv_fetcher.py
â”‚   â”œâ”€â”€ test_document_processor.py
â”‚   â”œâ”€â”€ test_rag_chain.py
â”‚   â””â”€â”€ test_integration.py
â”œâ”€â”€ data/                         # Data directory (not in git)
â”‚   â”œâ”€â”€ raw/                      # Raw API responses
â”‚   â”œâ”€â”€ processed/                # Processed documents
â”‚   â””â”€â”€ cache/                    # API response cache
â”œâ”€â”€ vector_db/                    # Vector store (not in git)
â”œâ”€â”€ logs/                         # Application logs (not in git)
â”œâ”€â”€ scripts/                      # Utility scripts
â”‚   â”œâ”€â”€ fetch_papers.py           # CLI for paper fetching
â”‚   â”œâ”€â”€ create_vector_db.py       # CLI for vector DB creation
â”‚   â””â”€â”€ evaluate_retrieval.py    # Evaluation script
â””â”€â”€ docs/                         # Extended documentation
    â”œâ”€â”€ phase_guides/
    â”‚   â”œâ”€â”€ phase1.md
    â”‚   â””â”€â”€ phase2.md
    â”œâ”€â”€ api_reference.md
    â””â”€â”€ architecture_diagrams/
```

---

## ğŸ”’ Security & Secrets Management

### API Key Storage
**NEVER** commit these to git:
- OpenAI API keys
- Anthropic API keys
- Any authentication tokens
- Database credentials

**Correct approach**:
```bash
# .env file (in .gitignore)
OPENAI_API_KEY=sk-...
ANTHROPIC_API_KEY=sk-ant-...
```

```python
# config.py
from dotenv import load_dotenv
import os

load_dotenv()

OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
if not OPENAI_API_KEY:
    raise ValueError("OPENAI_API_KEY not found in environment")
```

### .gitignore Requirements
```gitignore
# Secrets
.env
*.key
secrets/

# Data
data/
vector_db/
*.db

# Logs
logs/
*.log

# Python
__pycache__/
*.pyc
.pytest_cache/

# Jupyter
.ipynb_checkpoints/

# IDE
.vscode/
.idea/
```

---

## ğŸ“Š Data Management Rules

### Data Versioning
Raw data files include timestamps:
```
arxiv_papers_2024-01-15T14-30-00.json
pubmed_papers_2024-01-15T14-35-00.json
```

### Data Retention
- **Raw data**: Keep for 90 days minimum
- **Processed data**: Can be regenerated, keep for 30 days
- **Vector stores**: Persist indefinitely, version by date
- **Logs**: Keep for 30 days

### Data Size Limits
- Single file: <500MB
- Total raw data: <5GB per source
- Vector DB: <10GB for Phase 1-3
- If exceeded: Implement archival strategy

---

## ğŸ§ª Quality Assurance Standards

### Code Quality
- **Line length**: Max 100 characters
- **Function length**: Max 50 lines (prefer smaller)
- **Cyclomatic complexity**: Max 10
- **Type hints**: Required for all function signatures
- **Docstrings**: Required for all public functions

### Testing Requirements
**Phase 1**:
- Unit test coverage: >70%
- Integration tests: 3+ end-to-end scenarios

**Phase 4+**:
- Unit test coverage: >80%
- Agent behavior tests
- Regression tests for known edge cases

### Performance Benchmarks
Track these metrics:
- Paper fetch time: <2 seconds per paper
- Embedding time: <0.1 seconds per chunk
- Query time: <3 seconds (Phase 1)
- Memory usage: <2GB (Phase 1)

---

## ğŸ”„ Development Workflow

### Phase Completion Checklist
Before marking a phase complete:
- [ ] All features implemented and tested
- [ ] Documentation updated (README, AGENT.md, docstrings)
- [ ] Manual testing completed
- [ ] Performance benchmarks recorded
- [ ] Code reviewed (self-review minimum)
- [ ] Git commit with descriptive message
- [ ] Tag release (e.g., `v1.0-phase1`)

### Git Commit Standards
Format: `[PHASE] [TYPE]: Description`

Types:
- `feat`: New feature
- `fix`: Bug fix
- `docs`: Documentation
- `test`: Tests
- `refactor`: Code refactoring
- `perf`: Performance improvement

Examples:
```
[PHASE1] feat: Add ArXiv fetcher with rate limiting
[PHASE1] docs: Update AGENT.md with data rules
[PHASE2] feat: Integrate Semantic Scholar API
```

### Branch Strategy (Optional for Solo Project)
- `main`: Production-ready code
- `develop`: Integration branch
- `feature/phase-X-description`: Feature branches

---

## ğŸ“ Learning & Iteration Rules

### Rule of Progressive Refinement
1. **Make it work** (Phase 1-2)
2. **Make it right** (Phase 3-5)
3. **Make it fast** (Phase 6-8)
4. **Make it production-ready** (Phase 9-10)

### When to Refactor
Refactor when you notice:
- Code duplication (>3 times)
- Functions >50 lines
- Complex nested conditionals (>3 levels)
- Hard-to-test code
- Performance bottlenecks

### Technical Debt Tracking
Maintain `TODO.md` with:
- Known issues
- Optimization opportunities  
- Future enhancements
- Technical debt items

Format:
```markdown
## Phase 1 TODOs
- [ ] Add batch processing for large paper sets
- [ ] Implement async API calls
- [x] Add retry logic with exponential backoff

## Technical Debt
- Document processor could use caching (not critical for Phase 1)
- Consider switching to async/await in Phase 3
```

---

## ğŸš¨ Common Pitfalls to Avoid

### 1. **Over-Engineering Early**
âŒ Don't build abstract base classes in Phase 1
âœ… Start simple, refactor when you add 2nd implementation

### 2. **Ignoring Rate Limits**
âŒ Hammering APIs without delays
âœ… Respect rate limits, implement exponential backoff

### 3. **Poor Chunk Boundaries**
âŒ Splitting mid-sentence
âœ… Use RecursiveCharacterTextSplitter with semantic separators

### 4. **Metadata Loss**
âŒ Losing source information during processing
âœ… Propagate metadata through entire pipeline

### 5. **Premature Optimization**
âŒ Optimizing before profiling
âœ… Measure first, optimize bottlenecks only

### 6. **Insufficient Logging**
âŒ Silent failures
âœ… Log at appropriate levels, make debugging easy

### 7. **Hardcoded Paths**
âŒ `open('/Users/me/data/papers.json')`
âœ… Use `pathlib.Path` and config files

### 8. **No Error Recovery**
âŒ Crash on first API failure
âœ… Retry with backoff, graceful degradation

---

## ğŸ“ˆ Monitoring & Observability

### Metrics to Track (Per Phase)

**Phase 1**:
- Papers fetched (count, source)
- Chunks created (count, avg size)
- Embedding time
- Query latency
- Retrieval precision (manual eval)

**Phase 4+**:
- Agent decision distribution
- Query rewrite frequency
- Document grading scores
- Contradiction detection rate

**Phase 8+**:
- End-to-end latency
- API costs per query
- User satisfaction scores
- Error rates by component

### Logging Implementation
```python
import logging
from datetime import datetime

def setup_logging(component_name: str):
    """Standard logging configuration"""
    log_dir = Path("logs")
    log_dir.mkdir(exist_ok=True)
    
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    log_file = log_dir / f"{component_name}_{timestamp}.log"
    
    logging.basicConfig(
        level=logging.INFO,
        format='[%(asctime)s] [%(levelname)s] [%(name)s] %(message)s',
        handlers=[
            logging.FileHandler(log_file),
            logging.StreamHandler()
        ]
    )
    
    return logging.getLogger(component_name)
```

---

## ğŸ¤ Collaboration Guidelines (Future)

### Code Review Standards
- Check for rule compliance (this document)
- Verify tests pass
- Validate documentation
- Test manually if UI changes

### Communication
- Document design decisions in code comments
- Update AGENT.md when changing architecture
- Create issues for bugs/features
- Use clear commit messages

---

## ğŸ“š References & Resources

### Key Documentation
- [LangChain Docs](https://python.langchain.com/)
- [ArXiv API Guide](https://info.arxiv.org/help/api/index.html)
- [ChromaDB Docs](https://docs.trychroma.com/)
- [Sentence Transformers](https://www.sbert.net/)

### Research Papers
- "Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks" (RAG paper)
- "Self-RAG: Learning to Retrieve, Generate, and Critique through Self-Reflection"
- "Agentic Retrieval-Augmented Generation: A Survey on Agentic RAG"

### Best Practices
- [OpenAI RAG Best Practices](https://platform.openai.com/docs/guides/prompt-engineering)
- [LangChain RAG Patterns](https://python.langchain.com/docs/use_cases/question_answering/)

---

## ğŸ“ Version History

### v1.0.0-phase1 (Current)
- Initial project setup
- ArXiv integration
- Basic RAG pipeline
- Vector store with ChromaDB
- Simple Q&A interface

### Planned Versions
- v1.1.0-phase2: Multi-source integration
- v1.2.0-phase3: Router agent
- v1.3.0-phase4: Document grading
- v2.0.0-phase8: Full orchestration

---

## ğŸ¯ Success Definition

**Phase 1 is complete when**:
- âœ… 100+ ArXiv papers ingested
- âœ… Vector store created and persistent
- âœ… Query returns relevant results >70% of time
- âœ… Citations traceable to source
- âœ… All tests passing
- âœ… Documentation complete

**Project is complete when (Phase 10)**:
- ğŸ¯ Handles 10+ data sources
- ğŸ¯ Detects contradictions automatically
- ğŸ¯ Generates publication-ready reports
- ğŸ¯ Production deployed with auth
- ğŸ¯ <60s response time
- ğŸ¯ >85% user satisfaction

---

## ğŸ”„ Continuous Improvement

This document evolves with the project. Update it when:
- Architecture changes significantly
- New patterns emerge
- Rules need clarification
- Best practices discovered

**Last Updated**: 2024-01-15
**Next Review**: After Phase 2 completion

---

## ğŸ“ Support & Questions

For questions about this document or project architecture:
1. Review relevant phase guide in `docs/phase_guides/`
2. Check TODO.md for known issues
3. Consult referenced documentation
4. Document new patterns discovered

---

**Remember**: These rules exist to make development faster and more reliable in the long run. When in doubt, refer back to this document.

**Happy Building! ğŸš€**